{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import requests\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show, show_hist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import ast\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tif(tif_file):\n",
    "    tif_dataset = rio.open(tif_file)\n",
    "    return tif_dataset\n",
    "def print_tif(tif_dataset):\n",
    "    data = tif_dataset.read(1)  # Read the first band\n",
    "    no_data_value = tif_dataset.nodata\n",
    "    no_data_count = (data == no_data_value).sum()\n",
    "    print('dataset:\\n',tif_dataset)\n",
    "    print('\\nshape:\\n',tif_dataset.shape)\n",
    "    print('\\nno data value:\\n',tif_dataset.nodata)\n",
    "    print('\\nno data count:\\n',no_data_count)\n",
    "    print('\\nspatial extent:\\n',tif_dataset.bounds)\n",
    "    print('\\ncoordinate information (crs):\\n',tif_dataset.crs)\n",
    "def plot_tif(tif_dataset):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "    show(tif_dataset, ax=ax1);\n",
    "\n",
    "    show_hist(tif_dataset, bins=50, histtype='stepfilled',\n",
    "            lw=0.0, stacked=False, alpha=0.3, ax=ax2);\n",
    "    ax2.set_xlabel(tif_dataset.name.split('/')[-1].split('.')[0]);\n",
    "    ax2.get_legend().remove()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def info_tif(tif_dataset):\n",
    "    print_tif(tif_dataset)\n",
    "    plot_tif(tif_dataset)\n",
    "\n",
    "#mode: 0 stands for the larger the value is , the higher risk there will be a landslide, and 1 oppposite\n",
    "def recalssification_tif(tif_dataset,args,mode=0):\n",
    "    tif_data = tif_dataset.read(1)\n",
    "    tif_reclass = tif_data.copy()\n",
    "    no_class = len(args)+1\n",
    "    # Get the nodata value from the input raster and set it to 0 in the reclassified raster\n",
    "    nodata_value = tif_dataset.nodata\n",
    "    if nodata_value is not None:\n",
    "        tif_reclass[np.where(tif_data == nodata_value)] = 0\n",
    "    tif_reclass[np.where(tif_data==-9999.0)] = 0\n",
    "    if mode == 0:\n",
    "        if len(args) == 1:\n",
    "            tif_reclass[np.where((tif_data >= 0) & (tif_data <= args[0]))] = 1 \n",
    "            tif_reclass[np.where(tif_data > args[0])] = 2\n",
    "        elif len(args) == 2:\n",
    "            tif_reclass[np.where((tif_data >= 0) & (tif_data <= args[0]))] = 1 \n",
    "            tif_reclass[np.where((tif_data > args[0]) & (tif_data <= args[1]))] = 2\n",
    "            tif_reclass[np.where(tif_data > args[1])] = 3\n",
    "        elif len(args) == 3:\n",
    "            tif_reclass[np.where((tif_data >= 0) & (tif_data <= args[0]))] = 1 \n",
    "            tif_reclass[np.where((tif_data > args[0]) & (tif_data <= args[1]))] = 2\n",
    "            tif_reclass[np.where((tif_data > args[1]) & (tif_data <= args[2]))] = 3\n",
    "            tif_reclass[np.where(tif_data > args[2])] = 4\n",
    "    elif mode == 1:\n",
    "        if len(args) == 1:\n",
    "            tif_reclass[np.where((tif_data >= 0) & (tif_data <= args[0]))] = 2 \n",
    "            tif_reclass[np.where(tif_data > args[0])] = 1\n",
    "        elif len(args) == 2:\n",
    "            tif_reclass[np.where((tif_data >= 0) & (tif_data <= args[0]))] = 3 \n",
    "            tif_reclass[np.where((tif_data > args[0]) & (tif_data <= args[1]))] = 2\n",
    "            tif_reclass[np.where(tif_data > args[1])] = 1\n",
    "        elif len(args) == 3:\n",
    "            tif_reclass[np.where((tif_data >= 0) & (tif_data <= args[0]))] = 4\n",
    "            tif_reclass[np.where((tif_data > args[0]) & (tif_data <= args[1]))] = 3\n",
    "            tif_reclass[np.where((tif_data > args[1]) & (tif_data <= args[2]))] = 2\n",
    "            tif_reclass[np.where(tif_data > args[2])] = 1\n",
    "    '''\n",
    "    ext = [tif_dataset.bounds.left,\n",
    "        tif_dataset.bounds.right,\n",
    "        tif_dataset.bounds.bottom,\n",
    "        tif_dataset.bounds.top]\n",
    "    \n",
    "    \n",
    "    # Validate that there are enough indices provided for the classes\n",
    "    if no_class == 0:\n",
    "        raise ValueError(\"At least one class index must be provided for classification.\")\n",
    "    \n",
    "    # Generate a colormap with `no_class` distinct colors using the 'viridis' colormap\n",
    "    cmap = plt.get_cmap('viridis', no_class)\n",
    "    colormap_colors = cmap(np.arange(no_class))\n",
    "\n",
    "    \n",
    "    plt.figure(); \n",
    "    class_labels = [0,1,2,3]\n",
    "    \n",
    "    cmap = colors.ListedColormap(colormap_colors)\n",
    "    \n",
    "    # Create custom legend handles\n",
    "    legend_handles = [\n",
    "        mpatches.Patch(color=colormap_colors[i], label=class_labels[i])\n",
    "        for i in range(no_class)\n",
    "    ]\n",
    "    #cmap = colors.ListedColormap(['lightblue','yellow','orange','green','red'])\n",
    "    plt.imshow(tif_reclass,cmap=cmap,extent=ext)\n",
    "    plt.title(tif_dataset.name.split('/')[-1].split('.')[0])\n",
    "    ax=plt.gca(); ax.ticklabel_format(useOffset=False, style='plain') \n",
    "    rotatexlabels = plt.setp(ax.get_xticklabels(),rotation=90) \n",
    "    plt.legend(handles=legend_handles, loc='upper right')\n",
    "    '''\n",
    "    return tif_reclass\n",
    "\n",
    "# Read reclassification information for GLiM \n",
    "def read_reclassification_info(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    mapping = ast.literal_eval(lines[0].strip().split('=')[1].strip())\n",
    "    reclassification_info = {}\n",
    "    \n",
    "    for line in lines[2:]:\n",
    "        if '=' in line:\n",
    "            key, value = line.strip().split('=')\n",
    "            reclassification_info[key.strip()] = value.strip()\n",
    "    \n",
    "    return mapping, reclassification_info\n",
    "\n",
    "# Reclassify GLiM file using the reclassification information\n",
    "def recalssification_glim(data, mapping, reclassification_info, nodata):\n",
    "    reclassified_data = np.copy(data)\n",
    "    \n",
    "    for class_name, new_value in reclassification_info.items():\n",
    "        if new_value == 'ND':\n",
    "            new_value = nodata\n",
    "        else:\n",
    "            new_value = int(new_value)\n",
    "        \n",
    "        short_code = class_name.split('(')[1].split(')')[0].lower()\n",
    "        if short_code in mapping:\n",
    "            original_value = mapping[short_code]\n",
    "            reclassified_data[data == original_value] = new_value\n",
    "    \n",
    "    return reclassified_data\n",
    "\n",
    "#Read reclassification information for landform\n",
    "def read_reclassification_landform(file_path):\n",
    "    reclassification_mapping = {}\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if '=' in line:\n",
    "                old_value, new_value = line.strip().split('=')\n",
    "                reclassification_mapping[int(old_value.split(':')[0])] = int(new_value)\n",
    "    \n",
    "    return reclassification_mapping\n",
    "\n",
    "# Reclassify landform file using the reclassification information\n",
    "def reclassify_raster(data, reclassification_mapping,nodata):\n",
    "    reclassified_data = np.copy(data)\n",
    "    \n",
    "    for old_value, new_value in reclassification_mapping.items():\n",
    "        if new_value == 'ND':\n",
    "            new_value = nodata\n",
    "        else:\n",
    "            new_value = int(new_value)\n",
    "        reclassified_data[data == old_value] = new_value\n",
    "    \n",
    "    return reclassified_data\n",
    "\n",
    "def save_reclass_tif(tif_reclass,tif_dataset,save_path=r\".\\Tsunami_Risk_Zhimin\\02_reclassed\\on-shore\"):\n",
    "    reclassed_path=save_path\n",
    "    tif_name=tif_dataset.name.split('/')[-1]\n",
    "    output_file = os.path.join(reclassed_path, f'reclassified_{tif_name}')\n",
    "    out_meta = tif_dataset.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": tif_dataset.shape[0],\n",
    "        \"width\": tif_dataset.shape[1],\n",
    "        \"transform\": tif_dataset.transform,\n",
    "        \"crs\": tif_dataset.crs,\n",
    "        \"count\": 1,\n",
    "        \"nodata\": 0,\n",
    "        \"dtype\": 'int32'  \n",
    "    })\n",
    "        # Write the reclassified raster to the output file\n",
    "    with rio.open(output_file, 'w', **out_meta) as dst:\n",
    "        dst.write(tif_reclass, 1)\n",
    "    print(f'successfully saved at {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping: {'sm': 1, 'pa': 2, 'mt': 3, 'vi': 4, 'su': 5, 'sc': 6, 'vb': 7, 'ss': 8, 'wb': 9}\n",
      "Reclassification Info: {'Unconsolidated Sediments (SU)': '3', 'Siliciclastic Sedimentary Rocks (SS)': '2', 'Mixed Sedimentary Rocks (SM)': '2', 'Pyroclastic (PY)': '2', 'Carbonate Sedimentary Rocks (SC)': '2', 'Evaporites (EV)': '2', 'Metamorphic Rocks (MT)': '1', 'Acid Plutonic Rocks (PA)': '1', 'Intermediate Plutonic Rocks (PI)': '1', 'Basic Plutonic Rocks (PB)': '1', 'Acid Volcanic Rocks (VA)': '2', 'Intermediate Volcanic Rocks (VI)': '2', 'Basic Volcanic Rocks (VB)': '2', 'Ice and Glaciers (IG)': '0', 'Water Bodies (WB)': '0', 'No Data (ND)': 'ND'}\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_GLiM_on-shore.tif\n"
     ]
    }
   ],
   "source": [
    "# Example usage for reclassification of GLiM data\n",
    "file_path = r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\GLiM.txt'\n",
    "mapping, reclassification_info = read_reclassification_info(file_path)\n",
    "print(\"Mapping:\", mapping)\n",
    "print(\"Reclassification Info:\", reclassification_info)\n",
    "\n",
    "# change the file path to the location of the GLiM file\n",
    "glim=r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\03_raster_data\\coastal\\GLiM_on-shore.tif'\n",
    "glim_data=read_tif(glim)\n",
    "data=glim_data.read(1)\n",
    "nodata = glim_data.nodata\n",
    "reclassified_data = recalssification_glim(data, mapping, reclassification_info, nodata)  \n",
    "#save reclassified data to given path   \n",
    "save_path=r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test'\n",
    "save_reclass_tif(reclassified_data,glim_data,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassification Mapping: {1: 2, 2: 2, 3: 2, 4: 1, 5: 1, 6: 3, 7: 3, 8: 1, 9: 1, 10: 1}\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_Landforms_all.tif\n"
     ]
    }
   ],
   "source": [
    "# Example usage for reclassification of landform data\n",
    "file_path = r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\landform.txt'\n",
    "reclassification_mapping = read_reclassification_landform(file_path)\n",
    "print(\"Reclassification Mapping:\", reclassification_mapping)\n",
    "\n",
    "# change the file path to the location of the landform file\n",
    "LF=r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\03_raster_data\\coastal\\Landforms_all.tif'\n",
    "LF_data=read_tif(LF)\n",
    "dt=LF_data.read(1)\n",
    "nodata=-255\n",
    "rtf=reclassify_raster(dt,reclassification_mapping,nodata)\n",
    "#save reclassified data to given path   \n",
    "save_path=r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test'\n",
    "save_reclass_tif(rtf,LF_data,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster_folder C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\03_raster_data\\coastal\n",
      "save C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\n",
      "#input:filename,mode(0 stands for the larger the value is , the higher risk there will be a landslide, and 1 oppposite),threshold\n",
      "chirp_precipitation 0 1800 2200\n",
      "slope_on-shore 0 27 55\n",
      "distance_DLR_settlement 1 100 500\n",
      "#distance_earthquake_all 1 200 1000\n",
      "distance_faults_all 1 100 500\n",
      "distance_rivers_all 1 100 500\n",
      "#distance_valcano_all 1 1000 5000\n",
      "{'raster_folder': ['C:\\\\Users\\\\Zhimin.Chen\\\\Desktop\\\\ZChen\\\\tsunami\\\\Tsunami_Risk_Zhimin\\\\03_raster_data\\\\coastal'], 'save': ['C:\\\\Users\\\\Zhimin.Chen\\\\Desktop\\\\ZChen\\\\tsunami\\\\Tsunami_Risk_Zhimin\\\\02_reclassed\\\\test'], '#input:filename,mode(0': ['stands', 'for', 'the', 'larger', 'the', 'value', 'is', ',', 'the', 'higher', 'risk', 'there', 'will', 'be', 'a', 'landslide,', 'and', '1', 'oppposite),threshold'], 'chirp_precipitation': ['0', '1800', '2200'], 'slope_on-shore': ['0', '27', '55'], 'distance_DLR_settlement': ['1', '100', '500'], '#distance_earthquake_all': ['1', '200', '1000'], 'distance_faults_all': ['1', '100', '500'], 'distance_rivers_all': ['1', '100', '500'], '#distance_valcano_all': ['1', '1000', '5000']}\n"
     ]
    }
   ],
   "source": [
    "#read threshold information from txt file\n",
    "with open(r'C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\threshold.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Now 'lines' is a list where each element is a line from the file\n",
    "for line in lines:\n",
    "    print(line.strip())  # .strip() removes the newline character at the end\n",
    "directories = {}\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        line_split=line.split(' ')\n",
    "        key= line.split(' ')[0]\n",
    "        value= line.split(' ')[1:]\n",
    "        directories[key] = value\n",
    "\n",
    "print(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:filename,mode(0 is a comment, skipping...\n",
      "<open DatasetReader name='C:/Users/Zhimin.Chen/Desktop/ZChen/tsunami/Tsunami_Risk_Zhimin/03_raster_data/coastal/chirp_precipitation.tif' mode='r'> [1800.0, 2200.0] 0\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_chirp_precipitation.tif\n",
      "chirp_precipitation has been reclassified and saved successfully\n",
      "<open DatasetReader name='C:/Users/Zhimin.Chen/Desktop/ZChen/tsunami/Tsunami_Risk_Zhimin/03_raster_data/coastal/slope_on-shore.tif' mode='r'> [27.0, 55.0] 0\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_slope_on-shore.tif\n",
      "slope_on-shore has been reclassified and saved successfully\n",
      "<open DatasetReader name='C:/Users/Zhimin.Chen/Desktop/ZChen/tsunami/Tsunami_Risk_Zhimin/03_raster_data/coastal/distance_DLR_settlement.tif' mode='r'> [100.0, 500.0] 1\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_distance_DLR_settlement.tif\n",
      "distance_DLR_settlement has been reclassified and saved successfully\n",
      "distance_earthquake_all is a comment, skipping...\n",
      "<open DatasetReader name='C:/Users/Zhimin.Chen/Desktop/ZChen/tsunami/Tsunami_Risk_Zhimin/03_raster_data/coastal/distance_faults_all.tif' mode='r'> [100.0, 500.0] 1\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_distance_faults_all.tif\n",
      "distance_faults_all has been reclassified and saved successfully\n",
      "<open DatasetReader name='C:/Users/Zhimin.Chen/Desktop/ZChen/tsunami/Tsunami_Risk_Zhimin/03_raster_data/coastal/distance_rivers_all.tif' mode='r'> [100.0, 500.0] 1\n",
      "successfully saved at C:\\Users\\Zhimin.Chen\\Desktop\\ZChen\\tsunami\\Tsunami_Risk_Zhimin\\02_reclassed\\test\\reclassified_distance_rivers_all.tif\n",
      "distance_rivers_all has been reclassified and saved successfully\n",
      "distance_valcano_all is a comment, skipping...\n"
     ]
    }
   ],
   "source": [
    "# iterates through the directories and reclassifies the tif files\n",
    "raster_folder = directories['raster_folder'][0]\n",
    "save_folder = directories['save'][0]\n",
    "\n",
    "for key in list(directories.keys())[2:]:\n",
    "    if key[0]=='#':\n",
    "        print(f'{key[1:]} is a comment, skipping...')\n",
    "        continue\n",
    "    tif_key = key\n",
    "    tif_name=tif_key+'.tif'\n",
    "    tif_path= os.path.join(raster_folder, tif_name)\n",
    "    tif_dataset = read_tif(tif_path)   \n",
    "    tif_data = tif_dataset.read(1)\n",
    "    no_class = len(directories[key])\n",
    "    args = directories[key][1:]\n",
    "    args = [float(i) for i in args]\n",
    "    tif_mode = int(directories[key][0])\n",
    "    \n",
    "    # Convert args to the appropriate data type\n",
    "    print(tif_dataset,args,tif_mode)\n",
    "    reclassified_tif = recalssification_tif(tif_dataset,args,mode=tif_mode)\n",
    "    save_reclass_tif(reclassified_tif, tif_dataset, save_folder)\n",
    "    print(f'{key} has been reclassified and saved successfully')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
